Machine learning 
###################
to teach the machine
machine give us output after studying and give us prediction 
#Based on data set machine learn
 
credict_score                 interest-rate
>>>..>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
900                            6.5
500                            11.0
800                            5.6
550                            .
750                            .
#############################################
credict_score                 find

##EXAM
1)fIRST
2) SECOND
3)university
PDF,CHATGPT,TEXTBOOK,YOUTUBE,NOTEBOOK,
####################sslc
1)half++++>68
2)model+++>71
3)public++>74
#Evaluating the performance of machine
#and learn the machine repetedly
+++++++++++++++++++++++++++++++++++++++
#Two type of programming languages
+++++++++++++++++++++++++++++++++++++++++
1.Traditional Programming
2.Machine Learning Programming
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Teaches the machine based on dataset
##########################################
we teaches the machine the output and input
###########################################
eg.a person is a diabetics patient or not
input and output is present in the data
###########################################
using input generate output traditional way of programming
eg.how to find a prime number we use the logic and find the output
###################################################
machine learning programming
input =========> output
prediction based on the input and output
Traditional Programming
>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#HOUSE
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
.room -5
.kitchen
.hall
.dinning hall
.car+po
.blcony
######################
cash -input
home- output
########################
Type of ML
-supervised ML-eg,driving school
input===>output===>training===>model===>prediction
-unsupervised ML
######################
Here are some commonly used **supervised learning algorithms**:

### **Regression Algorithms** (Used for predicting continuous values):
1. **Linear Regression**
2. **Polynomial Regression**
3. **Ridge Regression**
4. **Lasso Regression**
5. **ElasticNet Regression**

### **Classification Algorithms** (Used for predicting categorical values):
1. **Logistic Regression**
2. **Support Vector Machine (SVM)**
3. **K-Nearest Neighbors (KNN)**
4. **Decision Tree**
5. **Random Forest**
6. **Gradient Boosting Machines (GBM)**
7. **XGBoost**
8. **LightGBM**
9. **CatBoost**
10. **Naive Bayes**

These algorithms are commonly used for both binary and multiclass classification tasks. Supervised learning algorithms require labeled datasets and are typically used for tasks like prediction, classification, and regression.
---------------------------
SUPERVISED MACHINE LEARNING|
---------------------------
Classification
###################
categorical data-to predict
Y/N,0/1,T/F
based on credict score interest rate reduce or not
iris dataset,diabectics or not
**K-Nearest Neighbors (KNN)**
neigh bayers algorithm
SVM-Support Vector Machine
descision tree
random forrest
/////////////////////////////////////
Regression
###########
if i want to predict a numerical/continous data we use regression model
how many cm rain i get tomorrow
value prediction
year/salary
simple linear regression
multiple linear regression
polynomial regression
#######################################################################
UNSUPERVISED ML
--------------------------
Data Contain more input samples
Unlabeled data
input has to be studied an input based on output is to be find
-clustering
more patients it became a cluster
input samples to group in clustering
-----------------------------------------
market segmentation                      |
#-----------------------------------------------------#
-how to improve a business 
-dress-trends,all are not provided with same offers 
,zudio
,westisides,lulu,fashions
-completed using clustering
JEWELLERY
-diamond
-platinum
-silver
-coins
-gold-rose gold
making charge different for all jewelleries
#------------------------------------------------------#
STEPS IN ML
1)Data Collection
2)Data Preparation and Exploration
3)Performance Evaluation
4)Model improvement and Deployment
############################################################
DATA COLLECTION
##########################################################
diabectics-not/yes dibectics collect
Kaggle
git
data
or from the source
----------------------------------------------------------
############################################################
DATA PREPARATION AND EXPLORATION
############################################################
Before Data Cleaning we do visualization(data Exploration)
Data cleaning-missing value handling/outliers/feature selection
feature engineering
############################################################
3)MODEL CREATION
Training of data model Creation
############################################################
4)PERFORMANCE EVALUATION
############################################################

############################################################
4)Model improvement and Deployment
############################################################
Release created model
############################################################
#TRAINING -to TEACH THE MACHINE-70%
Testing-check if the machine study well-30%
#INPUT_FEATURES-eg.pregnency ,glucose 
This usually refers to the variables or attributes used as inputs to a machine learning model. These are the features that the model uses to make predictions or classifications.

#output_Features-Column we need to predict-diabetic
This likely refers to the target variables or the outcomes that the model is trying to predict based on the input features.
#Class_labels-what we want to predict. yes/no
In classification problems, these are the categories or classes that the model is trying to predict. For example, in a binary classification problem, the class labels might be "positive" and "negative

#Input_labels-
This could refer to the names or descriptions of the input features, helping to identify what each feature represents.

#INPUT_FEATURES
Square footage
Number of bedrooms
Number of bathrooms
Lot size
Year built

#output_Features
House price (in dollars)

#Class_labels (if we were to categorize prices)
Low-priced
Medium-priced
High-priced

#Input_labels
sq_ft: Square footage of the house
num_bedrooms: Number of bedrooms
num_bathrooms: Number of bathrooms
lot_size: Size of the lot in square feet
year_built: Year the house was constructed
##supervised
####################################################################################################################
#Classification
___________________________________________________________________________________________________________________________________________
\1.KNN              K nearest neighbours-check note book page 1
___________________________________________________________________________________________________________________________________________
supervised
-Used for classification and regression
-Majority used for Classification-predict categorical variable
-worked on distance formula/Eucledian formula
root((x2-x1)^2+(y2-y1)^2)
don't except 100 percent prediction
-distance calculated for k=5
so may square and circles
a point is taken and want to predict if it is square or circle.
Distance from the point to all squares and circle
take the Circle square which is more closer
 from sklearn.neighbors import KneighborsClassifier

-COLAB STARTED
10-10-24
___________________________________________________________________________________________________________________________________________
Train test split using knn
train_test_split of model_selection module of sklearn package
NORMALIZATION TO GIVE EQUAL IMPORTANTS TO ALL THE COLUMNS
EG:if the glucose column defines the dibectics because of the larger value the importants of other columns where gone tO PREVENT THIS WE HAVE TO NORMALIZE THE  column.ELSE the nmachine use the glucose clolumn mainly to predict dibectics.
TWO METHODS--

#STANDARD SCALAR-normaly used
equation-z=(x-u)/s
z:new value
x-orgibal value
u:mean 0f training data
s:standard deviation of training data
#MIN MAX SCALAR
model
fit-to collect values
fit done.transform()
#######
the model knn
model=Kneighbours(n_neighbors=7)
model.fit(x_train,y_train)
model.predict(x_test)
######################################################################################################################################
PERFORMANACE EVALUATION METHODS OF REGERSSION
____________________________________________________________________________________________________________________________________


1.accuracy score
2.recall
3.precision
4.F1_Score
__________________________________________________
ALL worked based on a metrics
CONFUSION METRICS-all the performance evaluaton matrix depends on
____________________________________________________________________________________________________

14-10-24
_______________________________________________________________________________________
CONFUSION MATRIX 
-technical terms in matrix
TP-1=1
TN=0=0
FP-0=1
FN-1=0
#ACCURACY SCORE
#RANDOM_STATE-To prevent repeated change in accuracy score
random_state=1
random_state=0
random-state=42
reproducability
____________________________________________________________________________________________________

15-10-24
iris_heart_csv in collab-note
heart.csv
confusion matrix
more that 2 outputs use confusion matrix display
accuracy_score



































 



 

